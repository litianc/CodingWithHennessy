# åç«¯æŠ€æœ¯æ–¹æ¡ˆè®¾è®¡

## ğŸ¯ æŠ€æœ¯æ ˆé€‰æ‹©

### æ ¸å¿ƒæ¡†æ¶
- **Node.js 20+** - é«˜æ€§èƒ½JavaScriptè¿è¡Œæ—¶
- **Express 4** - è½»é‡çº§Webåº”ç”¨æ¡†æ¶
- **TypeScript 5** - ç±»å‹å®‰å…¨çš„JavaScriptè¶…é›†

### å®æ—¶é€šä¿¡
- **Socket.IO** - WebSocketå®æ—¶é€šä¿¡æ¡†æ¶
- **Redis Adapter** - å¤šå®ä¾‹Socket.IOé€‚é…å™¨

### éŸ³é¢‘å¤„ç†
- **FFmpeg** - éŸ³é¢‘æ ¼å¼è½¬æ¢å’Œå¤„ç†
- **node-ffmpeg** - FFmpeg Node.jså°è£…
- **WebAssembly** - å®¢æˆ·ç«¯éŸ³é¢‘å¤„ç†

### æ•°æ®åº“å’Œç¼“å­˜
- **MongoDB 7.0** - æ–‡æ¡£å‹æ•°æ®åº“ï¼Œçµæ´»çš„æ•°æ®ç»“æ„
- **Redis 7.2** - å†…å­˜æ•°æ®åº“ï¼Œç¼“å­˜å’Œä¼šè¯å­˜å‚¨
- **Mongoose** - MongoDB ODMå·¥å…·

### æ¶ˆæ¯é˜Ÿåˆ—
- **Bull Queue** - åŸºäºRedisçš„ä»»åŠ¡é˜Ÿåˆ—
- **Agenda** - å®šæ—¶ä»»åŠ¡è°ƒåº¦

## ğŸ—ï¸ é¡¹ç›®æ¶æ„

### ç›®å½•ç»“æ„
```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ controllers/           # æ§åˆ¶å™¨å±‚
â”‚   â”‚   â”œâ”€â”€ meetingController.ts
â”‚   â”‚   â”œâ”€â”€ transcriptionController.ts
â”‚   â”‚   â”œâ”€â”€ voiceprintController.ts
â”‚   â”‚   â”œâ”€â”€ aiController.ts
â”‚   â”‚   â”œâ”€â”€ emailController.ts
â”‚   â”‚   â””â”€â”€ uploadController.ts
â”‚   â”œâ”€â”€ services/              # ä¸šåŠ¡é€»è¾‘å±‚
â”‚   â”‚   â”œâ”€â”€ meetingService.ts
â”‚   â”‚   â”œâ”€â”€ speechRecognition.ts
â”‚   â”‚   â”œâ”€â”€ voiceprintService.ts
â”‚   â”‚   â”œâ”€â”€ llmService.ts
â”‚   â”‚   â”œâ”€â”€ emailService.ts
â”‚   â”‚   â”œâ”€â”€ audioProcessor.ts
â”‚   â”‚   â””â”€â”€ fileStorage.ts
â”‚   â”œâ”€â”€ models/                # æ•°æ®æ¨¡å‹å±‚
â”‚   â”‚   â”œâ”€â”€ Meeting.ts
â”‚   â”‚   â”œâ”€â”€ Transcription.ts
â”‚   â”‚   â”œâ”€â”€ Participant.ts
â”‚   â”‚   â”œâ”€â”€ Voiceprint.ts
â”‚   â”‚   â”œâ”€â”€ MeetingMinutes.ts
â”‚   â”‚   â””â”€â”€ AIConversation.ts
â”‚   â”œâ”€â”€ middleware/            # ä¸­é—´ä»¶
â”‚   â”‚   â”œâ”€â”€ auth.ts
â”‚   â”‚   â”œâ”€â”€ validation.ts
â”‚   â”‚   â”œâ”€â”€ rateLimit.ts
â”‚   â”‚   â”œâ”€â”€ errorHandler.ts
â”‚   â”‚   â”œâ”€â”€ upload.ts
â”‚   â”‚   â””â”€â”€ cors.ts
â”‚   â”œâ”€â”€ websocket/             # WebSocketå¤„ç†
â”‚   â”‚   â”œâ”€â”€ socketHandler.ts
â”‚   â”‚   â”œâ”€â”€ meetingSocket.ts
â”‚   â”‚   â”œâ”€â”€ transcriptionSocket.ts
â”‚   â”‚   â””â”€â”€ voiceprintSocket.ts
â”‚   â”œâ”€â”€ routes/                # è·¯ç”±å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ index.ts
â”‚   â”‚   â”œâ”€â”€ meetings.ts
â”‚   â”‚   â”œâ”€â”€ transcriptions.ts
â”‚   â”‚   â”œâ”€â”€ voiceprints.ts
â”‚   â”‚   â”œâ”€â”€ ai.ts
â”‚   â”‚   â””â”€â”€ emails.ts
â”‚   â”œâ”€â”€ utils/                 # å·¥å…·å‡½æ•°
â”‚   â”‚   â”œâ”€â”€ logger.ts
â”‚   â”‚   â”œâ”€â”€ config.ts
â”‚   â”‚   â”œâ”€â”€ crypto.ts
â”‚   â”‚   â”œâ”€â”€ dateUtils.ts
â”‚   â”‚   â””â”€â”€ validation.ts
â”‚   â”œâ”€â”€ types/                 # ç±»å‹å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ meeting.ts
â”‚   â”‚   â”œâ”€â”€ transcription.ts
â”‚   â”‚   â”œâ”€â”€ voiceprint.ts
â”‚   â”‚   â”œâ”€â”€ api.ts
â”‚   â”‚   â””â”€â”€ socket.ts
â”‚   â”œâ”€â”€ jobs/                  # åå°ä»»åŠ¡
â”‚   â”‚   â”œâ”€â”€ audioProcessing.ts
â”‚   â”‚   â”œâ”€â”€ transcriptionProcessing.ts
â”‚   â”‚   â”œâ”€â”€ voiceprintTraining.ts
â”‚   â”‚   â””â”€â”€ emailSending.ts
â”‚   â””â”€â”€ app.ts                 # åº”ç”¨å…¥å£
â”œâ”€â”€ uploads/                   # æ–‡ä»¶ä¸Šä¼ ç›®å½•
â”œâ”€â”€ logs/                      # æ—¥å¿—æ–‡ä»¶
â”œâ”€â”€ tests/                     # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ nodemon.json
```

## ğŸ”§ æ ¸å¿ƒæœåŠ¡è®¾è®¡

### 1. SpeechRecognitionService - è¯­éŸ³è¯†åˆ«æœåŠ¡
```typescript
interface SpeechRecognitionService {
  // å®æ—¶è¯­éŸ³è¯†åˆ«
  startRealTimeRecognition(options: {
    meetingId: string;
    format: 'wav' | 'mp3' | 'webm';
    sampleRate: number;
    language: string;
  }): Promise<string>;

  // æ‰¹é‡è¯­éŸ³è¯†åˆ«
  processAudioFile(audioFile: Buffer, options: {
    format: string;
    sampleRate: number;
    language: string;
    enablePunctuation?: boolean;
    enableSpeakerDiarization?: boolean;
  }): Promise<TranscriptionResult>;

  // åœæ­¢è¯†åˆ«
  stopRecognition(sessionId: string): Promise<void>;

  // è·å–è¯†åˆ«ç»“æœ
  getTranscription(sessionId: string): Promise<TranscriptionSegment[]>;
}

interface TranscriptionResult {
  segments: TranscriptionSegment[];
  language: string;
  confidence: number;
  duration: number;
}
```

### 2. VoiceprintService - å£°çº¹è¯†åˆ«æœåŠ¡
```typescript
interface VoiceprintService {
  // æ³¨å†Œå£°çº¹
  registerVoiceprint(participantId: string, audioSamples: Buffer[]): Promise<Voiceprint>;

  // å®æ—¶å£°çº¹è¯†åˆ«
  identifySpeaker(audioSegment: Buffer, options?: {
    threshold?: number;
    topK?: number;
  }): Promise<VoiceprintMatch[]>;

  // å£°çº¹èšç±»
  clusterVoiceprints(segments: AudioSegment[]): Promise<VoiceprintCluster[]>;

  // è®­ç»ƒå£°çº¹æ¨¡å‹
  trainVoiceprintModel(voiceprintId: string, newSamples: Buffer[]): Promise<void>;

  // å£°çº¹ç‰¹å¾æå–
  extractFeatures(audioBuffer: Buffer): Promise<number[]>;
}

interface VoiceprintMatch {
  voiceprintId: string;
  participantId: string;
  confidence: number;
  similarity: number;
}
```

### 3. LLMService - å¤§è¯­è¨€æ¨¡å‹æœåŠ¡
```typescript
interface LLMService {
  // ç”Ÿæˆä¼šè®®çºªè¦
  generateMeetingMinutes(transcripts: TranscriptionSegment[], options?: {
    language?: string;
    format?: 'markdown' | 'html' | 'json';
    includeActionItems?: boolean;
    includeDecisions?: boolean;
  }): Promise<MeetingMinutes>;

  // ä¼˜åŒ–çºªè¦å†…å®¹
  optimizeContent(originalMinutes: MeetingMinutes, userRequest: string): Promise<MeetingMinutes>;

  // AIå¯¹è¯
  chatWithContext(messages: ChatMessage[], context: MeetingContext): Promise<ChatResponse>;

  // æ™ºèƒ½æ‘˜è¦
  generateSummary(content: string, maxLength?: number): Promise<string>;

  // æå–è¡ŒåŠ¨é¡¹
  extractActionItems(transcripts: TranscriptionSegment[]): Promise<ActionItem[]>;
}

interface MeetingMinutes {
  id: string;
  meetingId: string;
  title: string;
  date: Date;
  participants: string[];
  summary: string;
  topics: Topic[];
  actionItems: ActionItem[];
  decisions: Decision[];
  generatedAt: Date;
}
```

### 4. AudioProcessor - éŸ³é¢‘å¤„ç†æœåŠ¡
```typescript
interface AudioProcessor {
  // éŸ³é¢‘æ ¼å¼è½¬æ¢
  convertFormat(inputBuffer: Buffer, inputFormat: string, outputFormat: string): Promise<Buffer>;

  // éŸ³é¢‘é™å™ª
  denoiseAudio(audioBuffer: Buffer): Promise<Buffer>;

  // éŸ³é¢‘åˆ†æ®µ
  segmentAudio(audioBuffer: Buffer, segmentDuration: number): Promise<Buffer[]>;

  // éŸ³é¢‘è´¨é‡æ£€æµ‹
  analyzeAudioQuality(audioBuffer: Buffer): Promise<AudioQuality>;

  // å®æ—¶éŸ³é¢‘æµå¤„ç†
  processAudioStream(stream: Readable, options: {
    sampleRate: number;
    channels: number;
    format: string;
  }): Transform;
}

interface AudioQuality {
  signalToNoiseRatio: number;
  volumeLevel: number;
  clarity: number;
  hasNoise: boolean;
  recommendations: string[];
}
```

## ğŸ”Œ WebSocketäº‹ä»¶è®¾è®¡

### 1. ä¼šè®®ç›¸å…³äº‹ä»¶
```typescript
interface MeetingEvents {
  // å®¢æˆ·ç«¯ -> æœåŠ¡ç«¯
  'join-meeting': { meetingId: string; userId: string };
  'leave-meeting': { meetingId: string; userId: string };
  'start-recording': { meetingId: string };
  'stop-recording': { meetingId: string };
  'pause-recording': { meetingId: string };
  'resume-recording': { meetingId: string };

  // æœåŠ¡ç«¯ -> å®¢æˆ·ç«¯
  'meeting-joined': { meetingId: string; participants: Participant[] };
  'meeting-left': { meetingId: string; userId: string };
  'recording-started': { meetingId: string; timestamp: Date };
  'recording-stopped': { meetingId: string; duration: number };
  'meeting-status-changed': { meetingId: string; status: MeetingStatus };
  'participant-joined': { participant: Participant };
  'participant-left': { participantId: string };
}
```

### 2. è½¬å½•ç›¸å…³äº‹ä»¶
```typescript
interface TranscriptionEvents {
  // å®¢æˆ·ç«¯ -> æœåŠ¡ç«¯
  'audio-chunk': { meetingId: string; chunk: Buffer; timestamp: number };
  'transcription-correct': { segmentId: string; correctedText: string };

  // æœåŠ¡ç«¯ -> å®¢æˆ·ç«¯
  'transcription-update': { segment: TranscriptionSegment };
  'transcription-complete': { segments: TranscriptionSegment[] };
  'speaker-identified': { segmentId: string; speakerId: string; confidence: number };
  'transcription-error': { error: string; segmentId?: string };
}
```

### 3. AIå¤„ç†ç›¸å…³äº‹ä»¶
```typescript
interface AIEvents {
  // å®¢æˆ·ç«¯ -> æœåŠ¡ç«¯
  'generate-minutes': { meetingId: string; options?: GenerateOptions };
  'optimize-content': { minutesId: string; request: string };
  'ai-chat': { meetingId: string; message: string };

  // æœåŠ¡ç«¯ -> å®¢æˆ·ç«¯
  'ai-thinking-start': { type: 'minutes' | 'optimization' | 'chat' };
  'ai-thinking-stop': { type: 'minutes' | 'optimization' | 'chat' };
  'minutes-generated': { minutes: MeetingMinutes };
  'content-optimized': { minutes: MeetingMinutes; changes: string[] };
  'ai-chat-response': { message: ChatMessage };
  'ai-progress': { stage: string; progress: number; message?: string };
}
```

## ğŸ—„ï¸ æ•°æ®åº“æ¨¡å‹è®¾è®¡

### 1. Meetingæ¨¡å‹
```typescript
interface MeetingDocument {
  _id: ObjectId;
  title: string;
  description?: string;
  startTime: Date;
  endTime?: Date;
  participants: ObjectId[];
  status: 'scheduled' | 'in-progress' | 'processing' | 'completed';
  settings: {
    language: string;
    enableTranscription: boolean;
    enableVoiceprint: boolean;
    autoGenerateMinutes: boolean;
  };
  metadata: {
    duration?: number;
    audioFiles: string[];
    transcriptCount: number;
    participantCount: number;
  };
  createdBy: ObjectId;
  createdAt: Date;
  updatedAt: Date;
}
```

### 2. Transcriptionæ¨¡å‹
```typescript
interface TranscriptionDocument {
  _id: ObjectId;
  meetingId: ObjectId;
  segmentId: string;
  speakerId: ObjectId;
  speakerName: string;
  content: string;
  originalContent: string;
  confidence: number;
  timestamp: Date;
  duration: number;
  audioSegment?: {
    file: string;
    startTime: number;
    endTime: number;
  };
  corrections: Array<{
    correctedAt: Date;
    correctedBy: ObjectId;
    originalText: string;
    correctedText: string;
  }>;
  isFinal: boolean;
  processingStatus: 'processing' | 'completed' | 'error';
  createdAt: Date;
  updatedAt: Date;
}
```

### 3. Voiceprintæ¨¡å‹
```typescript
interface VoiceprintDocument {
  _id: ObjectId;
  participantId: ObjectId;
  name: string;
  email?: string;
  voiceFeatures: {
    embedding: number[];
    algorithm: string;
    version: string;
  };
  trainingSamples: Array<{
    file: string;
    duration: number;
    quality: number;
    recordedAt: Date;
  }>;
  accuracy: {
    overall: number;
    truePositive: number;
    falsePositive: number;
    lastUpdated: Date;
  };
  status: 'training' | 'active' | 'inactive';
  metadata: {
    gender?: string;
    age?: string;
    accent?: string;
    language: string;
  };
  createdAt: Date;
  updatedAt: Date;
}
```

## ğŸ” ä¸­é—´ä»¶è®¾è®¡

### 1. è®¤è¯ä¸­é—´ä»¶
```typescript
interface AuthMiddleware {
  verifyToken(req: Request, res: Response, next: NextFunction): void;
  generateToken(payload: any): string;
  refreshToken(refreshToken: string): Promise<string>;
  revokeToken(token: string): Promise<void>;
}

// ä½¿ç”¨ç¤ºä¾‹
app.use('/api/meetings', authenticateToken);
app.use('/api/voiceprints', authenticateToken);
```

### 2. é™æµä¸­é—´ä»¶
```typescript
interface RateLimitConfig {
  windowMs: number;
  max: number;
  message?: string;
  standardHeaders?: boolean;
  legacyHeaders?: boolean;
}

// APIé™æµ
const apiLimiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15åˆ†é’Ÿ
  max: 100, // æœ€å¤š100ä¸ªè¯·æ±‚
  message: 'Too many requests from this IP'
});

// éŸ³é¢‘ä¸Šä¼ é™æµ
const uploadLimiter = rateLimit({
  windowMs: 60 * 1000, // 1åˆ†é’Ÿ
  max: 10, // æœ€å¤š10ä¸ªæ–‡ä»¶
  message: 'Upload rate limit exceeded'
});
```

### 3. æ–‡ä»¶ä¸Šä¼ ä¸­é—´ä»¶
```typescript
interface UploadConfig {
  destination: string;
  filename: (req: Request, file: Express.Multer.File, cb: Function) => void;
  limits: {
    fileSize: number;
    files: number;
  };
  fileFilter: (req: Request, file: Express.Multer.File, cb: Function) => void;
}

const audioUpload = multer({
  storage: multer.diskStorage({
    destination: 'uploads/audio/',
    filename: (req, file, cb) => {
      const uniqueName = `${Date.now()}-${Math.round(Math.random() * 1E9)}`;
      cb(null, `${uniqueName}${path.extname(file.originalname)}`);
    }
  }),
  limits: {
    fileSize: 100 * 1024 * 1024, // 100MB
    files: 5
  },
  fileFilter: (req, file, cb) => {
    const allowedTypes = ['audio/wav', 'audio/mp3', 'audio/webm', 'audio/ogg'];
    cb(null, allowedTypes.includes(file.mimetype));
  }
});
```

## âš¡ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 1. ç¼“å­˜ç­–ç•¥
```typescript
// Redisç¼“å­˜é…ç½®
interface CacheConfig {
  meetings: {
    ttl: 3600; // 1å°æ—¶
    prefix: 'meeting:';
  };
  transcriptions: {
    ttl: 1800; // 30åˆ†é’Ÿ
    prefix: 'transcription:';
  };
  voiceprints: {
    ttl: 86400; // 24å°æ—¶
    prefix: 'voiceprint:';
  };
  aiResults: {
    ttl: 7200; // 2å°æ—¶
    prefix: 'ai:';
  };
}

// ç¼“å­˜æœåŠ¡å®ç°
class CacheService {
  async get<T>(key: string): Promise<T | null>;
  async set(key: string, value: any, ttl?: number): Promise<void>;
  async del(key: string): Promise<void>;
  async invalidatePattern(pattern: string): Promise<void>;
}
```

### 2. æ•°æ®åº“ä¼˜åŒ–
```typescript
// MongoDBç´¢å¼•é…ç½®
const indexes = [
  // ä¼šè®®ç´¢å¼•
  { collection: 'meetings', index: { createdBy: 1, createdAt: -1 } },
  { collection: 'meetings', index: { status: 1, startTime: -1 } },

  // è½¬å½•ç´¢å¼•
  { collection: 'transcriptions', index: { meetingId: 1, timestamp: 1 } },
  { collection: 'transcriptions', index: { speakerId: 1, timestamp: -1 } },

  // å£°çº¹ç´¢å¼•
  { collection: 'voiceprints', index: { participantId: 1 } },
  { collection: 'voiceprints', index: { 'voiceFeatures.embedding': '2dsphere' } }
];

// è¿æ¥æ± é…ç½®
const mongoOptions = {
  maxPoolSize: 10,
  serverSelectionTimeoutMS: 5000,
  socketTimeoutMS: 45000,
  bufferMaxEntries: 0,
  bufferCommands: false
};
```

### 3. éŸ³é¢‘å¤„ç†ä¼˜åŒ–
```typescript
// éŸ³é¢‘å¤„ç†é˜Ÿåˆ—
const audioProcessingQueue = new Bull('audio-processing', {
  redis: { port: 6379, host: 'redis' },
  defaultJobOptions: {
    removeOnComplete: 100,
    removeOnFail: 50,
    attempts: 3,
    backoff: 'exponential'
  }
});

// æ‰¹é‡å¤„ç†ä¼˜åŒ–
class AudioBatchProcessor {
  private batchSize = 10;
  private processingInterval = 5000; // 5ç§’

  async addToBatch(audioChunk: AudioChunk): Promise<void>;
  async processBatch(): Promise<ProcessedResult[]>;
  async flushBatch(): Promise<void>;
}
```

## ğŸ”§ é…ç½®ç®¡ç†

### 1. ç¯å¢ƒé…ç½®
```typescript
interface AppConfig {
  server: {
    port: number;
    host: string;
    cors: {
      origin: string[];
      credentials: boolean;
    };
  };
  database: {
    mongodb: {
      uri: string;
      options: any;
    };
    redis: {
      host: string;
      port: number;
      password?: string;
    };
  };
  services: {
    alibabaCloud: {
      accessKeyId: string;
      accessKeySecret: string;
      region: string;
    };
    deepseek: {
      apiKey: string;
      baseURL: string;
      model: string;
    };
    email: {
      host: string;
      port: number;
      secure: boolean;
      auth: {
        user: string;
        pass: string;
      };
    };
  };
  upload: {
    maxFileSize: number;
    allowedFormats: string[];
    storagePath: string;
  };
  websocket: {
    cors: {
      origin: string[];
      credentials: boolean;
    };
    pingTimeout: number;
    pingInterval: number;
  };
}
```

### 2. æ—¥å¿—é…ç½®
```typescript
// Winstonæ—¥å¿—é…ç½®
const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.errors({ stack: true }),
    winston.format.json()
  ),
  defaultMeta: { service: 'meeting-agent-backend' },
  transports: [
    new winston.transports.File({ filename: 'logs/error.log', level: 'error' }),
    new winston.transports.File({ filename: 'logs/combined.log' }),
    new winston.transports.Console({
      format: winston.format.simple()
    })
  ]
});
```

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### 1. å•å…ƒæµ‹è¯•
```typescript
// Jestæµ‹è¯•é…ç½®
module.exports = {
  preset: 'ts-jest',
  testEnvironment: 'node',
  roots: ['<rootDir>/src', '<rootDir>/tests'],
  testMatch: ['**/__tests__/**/*.ts', '**/?(*.)+(spec|test).ts'],
  collectCoverageFrom: [
    'src/**/*.ts',
    '!src/**/*.d.ts',
    '!src/types/**'
  ],
  coverageThreshold: {
    global: {
      branches: 80,
      functions: 80,
      lines: 80,
      statements: 80
    }
  }
};
```

### 2. é›†æˆæµ‹è¯•
```typescript
// APIé›†æˆæµ‹è¯•ç¤ºä¾‹
describe('Meeting API', () => {
  let app: Express;

  beforeAll(async () => {
    app = await createTestApp();
  });

  afterAll(async () => {
    await cleanupTestApp();
  });

  describe('POST /api/meetings', () => {
    it('should create a new meeting', async () => {
      const meetingData = {
        title: 'Test Meeting',
        description: 'Test Description'
      };

      const response = await request(app)
        .post('/api/meetings')
        .set('Authorization', 'Bearer test-token')
        .send(meetingData)
        .expect(201);

      expect(response.body).toHaveProperty('_id');
      expect(response.body.title).toBe(meetingData.title);
    });
  });
});
```

## ğŸš€ éƒ¨ç½²å’Œç›‘æ§

### 1. å¥åº·æ£€æŸ¥
```typescript
// å¥åº·æ£€æŸ¥ç«¯ç‚¹
app.get('/health', async (req, res) => {
  const health = {
    status: 'ok',
    timestamp: new Date().toISOString(),
    uptime: process.uptime(),
    checks: {
      database: await checkDatabaseHealth(),
      redis: await checkRedisHealth(),
      externalServices: await checkExternalServices()
    }
  };

  const isHealthy = Object.values(health.checks).every(check => check.status === 'ok');
  res.status(isHealthy ? 200 : 503).json(health);
});
```

### 2. ç›‘æ§å’ŒæŒ‡æ ‡
```typescript
// PrometheusæŒ‡æ ‡
const promClient = require('prom-client');

const httpRequestDuration = new promClient.Histogram({
  name: 'http_request_duration_seconds',
  help: 'Duration of HTTP requests in seconds',
  labelNames: ['method', 'route', 'status_code']
});

const activeMeetings = new promClient.Gauge({
  name: 'active_meetings_total',
  help: 'Number of active meetings'
});

const transcriptionQueueSize = new promClient.Gauge({
  name: 'transcription_queue_size',
  help: 'Size of transcription processing queue'
});
```

### 3. é”™è¯¯å¤„ç†
```typescript
// å…¨å±€é”™è¯¯å¤„ç†ä¸­é—´ä»¶
const errorHandler = (
  error: Error,
  req: Request,
  res: Response,
  next: NextFunction
) => {
  logger.error('Unhandled error:', {
    error: error.message,
    stack: error.stack,
    url: req.url,
    method: req.method,
    ip: req.ip,
    userAgent: req.get('User-Agent')
  });

  if (res.headersSent) {
    return next(error);
  }

  const status = error.status || 500;
  const message = process.env.NODE_ENV === 'production'
    ? 'Internal Server Error'
    : error.message;

  res.status(status).json({
    success: false,
    error: {
      message,
      ...(process.env.NODE_ENV !== 'production' && { stack: error.stack })
    }
  });
};
```